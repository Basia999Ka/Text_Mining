{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barbara Kania\n",
    "### Wektoryzacja w spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zadanie 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przeanalizować, czy pojawia się sarkazm i ironia w toksycznych komentarzach, szukając niezgodności między dosłownym znaczeniem a kontekstem emocjonalnym. Wykorzystać wektoryzację, aby analizować podobieństwo semantyczne komentarzy do przeciwstawnych emocji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593336</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>What a breathe of fresh air to have someone wh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>151356</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>756192</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Your jewish friends were the ones who told you...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>158493</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5407051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Possible collusion by Trump and his affiliates...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>343435</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5808132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Exactly.  We need a % of GDP spending cap at t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>368584</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>557013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>By your own comment, even if some of them vote...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>149754</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    target                                       comment_text  \\\n",
       "0   593336  0.166667  What a breathe of fresh air to have someone wh...   \n",
       "1   756192  0.600000  Your jewish friends were the ones who told you...   \n",
       "2  5407051  0.000000  Possible collusion by Trump and his affiliates...   \n",
       "3  5808132  0.000000  Exactly.  We need a % of GDP spending cap at t...   \n",
       "4   557013  0.000000  By your own comment, even if some of them vote...   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack    insult  threat  asian  \\\n",
       "0              0.0      0.0              0.0  0.166667     0.0    NaN   \n",
       "1              0.2      0.0              0.6  0.400000     0.0    0.0   \n",
       "2              0.0      0.0              0.0  0.000000     0.0    NaN   \n",
       "3              0.0      0.0              0.0  0.000000     0.0    NaN   \n",
       "4              0.0      0.0              0.0  0.000000     0.0    NaN   \n",
       "\n",
       "   atheist  ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "0      NaN  ...      151356  approved      0    0    0      4         0   \n",
       "1      0.0  ...      158493  approved      0    0    0      0         0   \n",
       "2      NaN  ...      343435  approved      0    0    0      1         0   \n",
       "3      NaN  ...      368584  approved      0    0    0      7         0   \n",
       "4      NaN  ...      149754  approved      0    0    0      1         0   \n",
       "\n",
       "   sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "0              0.0                         0                         6  \n",
       "1              0.0                         6                        10  \n",
       "2              0.0                         0                         4  \n",
       "3              0.0                         0                         4  \n",
       "4              0.0                         0                         4  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "# model spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#Pobranie danych\n",
    "df = pd.read_csv('sample.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przetwarzanie tekstu za pomocą spaCy\n",
    "def get_vector(text):\n",
    "    doc = nlp(text)\n",
    "    return doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja wykrywająca sarkazm\n",
    "def get_sarcasm(text_vector):\n",
    "    # Tworzenie wektorów emocji\n",
    "    pos_emotions = nlp(\"happiness excitement enjoyment love optimism\").vector\n",
    "    neg_emotions = nlp(\"sadness frustration anger anxiety annoyance disappointment grief\").vector\n",
    "\n",
    "    # Obliczanie podobieństwa z emocjami\n",
    "    positive_similarity = cosine_similarity([text_vector], [pos_emotions])[0][0]\n",
    "    negative_similarity = cosine_similarity([text_vector], [neg_emotions])[0][0]\n",
    "\n",
    "    if negative_similarity > positive_similarity:\n",
    "        return 'Prawdopodobieństwo sarkazmu lub ironi'\n",
    "    else:\n",
    "        return 'Brak sarkazmu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sarcasm_detection'] = df['comment_text'].apply(lambda text: get_sarcasm(get_vector(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               Brak sarkazmu\n",
       "1                               Brak sarkazmu\n",
       "2                               Brak sarkazmu\n",
       "3                               Brak sarkazmu\n",
       "4       Prawdopodobieństwo sarkazmu lub ironi\n",
       "                        ...                  \n",
       "9995                            Brak sarkazmu\n",
       "9996                            Brak sarkazmu\n",
       "9997    Prawdopodobieństwo sarkazmu lub ironi\n",
       "9998                            Brak sarkazmu\n",
       "9999                            Brak sarkazmu\n",
       "Name: sarcasm_detection, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sarcasm_detection']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zadanie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla książek Anna Karenina oraz Jane Eyre - Wyodrębnić opisy i dialogi wybranych bohaterów, np. Anny, Aleksieja, Jane i Edwarda. Obliczyć podobieństwa semantyczne między bohaterami i określić, jak różne są ich osobowości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie książek\n",
    "with open('anna_karenina.txt', 'r', encoding='utf-8') as file:\n",
    "    book1 = file.read()\n",
    "with open('jane_eyre.txt', 'r', encoding='utf-8') as file:\n",
    "    book2 = file.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Czyszczenie tekstów książek\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'(\\*\\*\\*.*?\\*\\*\\*)', '', text, flags=re.DOTALL) \n",
    "    text = re.sub(r'[^\\w\\s\\.\\,\\']', '', text)  \n",
    "    return text\n",
    "\n",
    "book1_clean = clean_text(book1)\n",
    "book2_clean = clean_text(book2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dialogues_and_descriptions(text, character_name, context_sentences=1):\n",
    "    sentences = text.split('.')\n",
    "    extracted_sentences = []\n",
    "    \n",
    "    # Kontekst (poprzednie i następne zdania)\n",
    "    for i, sent in enumerate(sentences):\n",
    "        if character_name.lower() in sent.lower():\n",
    "            start = max(i - context_sentences, 0)\n",
    "            end = min(i + context_sentences + 1, len(sentences))\n",
    "            extracted_sentences.extend(sentences[start:end])\n",
    "    combined_text = ' '.join(extracted_sentences)\n",
    "    doc = nlp(combined_text)\n",
    "    return doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funkcja do obliczania podobieństwa semantycznego\n",
    "def calculate_similarity(vec1, vec2):\n",
    "    return cosine_similarity([vec1], [vec2])[0][0]\n",
    "\n",
    "# Funkcja do porównania podobieństwa między bohaterami\n",
    "def compare_characters(char_1_vector, char_2_vector):\n",
    "    similarity = calculate_similarity(char_1_vector, char_2_vector)\n",
    "    return similarity\n",
    "\n",
    "anna = extract_dialogues_and_descriptions(book1_clean, \"Anna\")\n",
    "jane = extract_dialogues_and_descriptions(book2_clean, \"Jane\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podobieństwo semantyczne między Anną a Jane: 0.9631704\n"
     ]
    }
   ],
   "source": [
    "similarity_Anna_Jane= compare_characters(anna, jane)\n",
    "print(\"Podobieństwo semantyczne między Anną a Jane:\", similarity_Anna_Jane)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexey = extract_dialogues_and_descriptions(book1_clean, \"Alexey\")\n",
    "edward = extract_dialogues_and_descriptions(book2_clean, \"Edward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podobieństwo semantyczne między Aleksiej a Edward: 0.9510137\n"
     ]
    }
   ],
   "source": [
    "similarity_Alexey_Edward = compare_characters(alexey, edward)\n",
    "print(\"Podobieństwo semantyczne między Aleksiej a Edward:\", similarity_Alexey_Edward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
