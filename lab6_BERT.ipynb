{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Wykorzystać model BERT do klasyfikacji tekstu, aby rozpoznać, z której powieści (Anna Karenina lub Jane Eyre) pochodzi dany fragment tekstu.\n",
    "\n",
    "\n",
    "1. Przygotuj dane wejściowe:\n",
    "   - Podziel teksty obu powieści na fragmenty o stałej długości (np. 100 słów lub 5 zdań).\n",
    "   - Przypisz etykiety: `0` dla *Anna Karenina*, `1` dla *Jane Eyre*.\n",
    "2. Skorzystaj z modelu `BertForSequenceClassification` do klasyfikacji tekstu.\n",
    "3. Przeprowadź fine-tuning modelu na przygotowanym zbiorze danych.\n",
    "4. Oceń skuteczność modelu na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import classification_report\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  \n",
    "nlp.max_length = 2000000\n",
    "\n",
    "def clean_text(text):\n",
    "    doc = nlp(text)\n",
    "    cleaned_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "def split_text_into_chunks(text, chunk_size=100):\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "with open('anna_karenina.txt', 'r', encoding='utf-8') as file_anna:\n",
    "    book1 = file_anna.read()\n",
    "\n",
    "with open('jane_eyre.txt', 'r', encoding='utf-8') as file_jane:\n",
    "    book2 = file_jane.read()\n",
    "\n",
    "anna_clean = clean_text(book1)\n",
    "jane_clean = clean_text(book2)\n",
    "\n",
    "anna_chunks = split_text_into_chunks(anna_clean, chunk_size=100)\n",
    "jane_chunks = split_text_into_chunks(jane_clean, chunk_size=100)\n",
    "\n",
    "texts = anna_chunks + jane_chunks\n",
    "labels = [0] * len(anna_chunks) + [1] * len(jane_chunks)\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizer BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# Dataset\n",
    "train_dataset = TextDataset(train_encodings, train_labels)\n",
    "test_dataset = TextDataset(test_encodings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# Model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "def encode_data(texts, tokenizer, max_length=100):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "\n",
    "train_encodings = encode_data(train_texts, tokenizer)\n",
    "test_encodings = encode_data(test_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trening modelu\n",
    "def train_model(model, data_loader, optimizer):\n",
    "    model.train() \n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = total_loss / len(data_loader)  \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels_batch = batch['labels']\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            labels.extend(labels_batch.cpu().numpy())\n",
    "\n",
    "            correct += (preds == labels_batch).sum().item()\n",
    "            total += labels_batch.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy, predictions, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6864771095189182\n",
      "Epoch 2, Loss: 0.6856086790561676\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "for i in range(n):\n",
    "    avg_loss = train_model(model, train_loader, optimizer)\n",
    "    print(f\"Epoch {i+1}, Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.50%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Anna Karenina       0.65      0.93      0.76       287\n",
      "    Jane Eyre       0.27      0.05      0.08       153\n",
      "\n",
      "     accuracy                           0.62       440\n",
      "    macro avg       0.46      0.49      0.42       440\n",
      " weighted avg       0.52      0.62      0.53       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, predictions, labels = evaluate_model(model, test_loader)\n",
    "# Wyniki\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(labels, predictions, target_names=[\"Anna Karenina\", \"Jane Eyre\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Wykorzystać model BERT do analizy toksyczności komentarzy.\n",
    "\n",
    "\n",
    "1. Załaduj zbiór danych o toksycznych komentarzach(dostępny na platformie).\n",
    "2. Skorzystaj z modelu `BertForSequenceClassification` i przeprowadź fine-tuning na tym zbiorze danych.\n",
    "3. Oceń model na zbiorze testowym i zinterpretuj wyniki.\n",
    "4. Przeprowadź analizę – znajdź komentarze, które model zaklasyfikował jako toksyczne, a które jako neutralne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sample.csv\")  \n",
    "def get_toxic_comment(x):\n",
    "    if x >= 0.5:\n",
    "        return 1  \n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "df['target'] = df['target'].apply(get_toxic_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Basia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class CommentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt') \n",
    "        return { \n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df['comment_text'].values, df['target'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Dataset\n",
    "train_dataset = CommentDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = CommentDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch_data['input_ids']\n",
    "        attention_mask = batch_data['attention_mask']\n",
    "        labels = batch_data['labels']\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_data in data_loader:\n",
    "            input_ids = batch_data['input_ids']\n",
    "            attention_mask = batch_data['attention_mask']\n",
    "            labels = batch_data['labels']\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(output.logits, dim=1)\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "    return total_correct / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.2252\n",
      "Epoch 2, Average Loss: 0.1425\n",
      "Epoch 3, Average Loss: 0.0875\n",
      "Test Set Accuracy: 93.35%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 4):\n",
    "    avg_loss = train_model(model, train_loader, optimizer)\n",
    "    print(f\"Epoch {epoch}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "test_accuracy = evaluate_model(model, test_loader)\n",
    "print(f\"Test Set Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.97      0.96      0.96      1858\n",
      "       Toxic       0.53      0.63      0.57       142\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.75      0.79      0.77      2000\n",
      "weighted avg       0.94      0.93      0.94      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predykcje i analiza wyników\n",
    "def predict_and_analyze(model, data_loader):\n",
    "    model.eval()\n",
    "    labels_list = []\n",
    "    predictions_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in data_loader:\n",
    "            input_ids = batch_data['input_ids']\n",
    "            attention_mask = batch_data['attention_mask']\n",
    "            labels = batch_data['labels']\n",
    "\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(output.logits, dim=1)\n",
    "\n",
    "            labels_list.extend(labels.cpu().numpy())\n",
    "            predictions_list.extend(predictions.cpu().numpy())\n",
    "\n",
    "    return labels_list, predictions_list\n",
    "\n",
    "actual_labels, predicted_labels = predict_and_analyze(model, test_loader)\n",
    "print(classification_report(actual_labels, predicted_labels, target_names=[\"Neutral\", \"Toxic\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Toxic Comments:\n",
      "[\"Trump is under investigation for his Russian ties, and he just proved that he's a White Supremacist sympathizer, if he isn't one himself.\", 'nobody has to work very hard to prove that the vile and disgusting so-called president is a racist, a bigot, and a hate-monger\\n\\njust sit at your computer and google Trump - Central park 5', 'oh crap...I live on the Oregon Coast!', 'Poor Jeremy.', \"Yes ...... It takes a real fool to ignore the fact that the Dixiecrats all became Republicans back in the Johnson Administration.\\n.\\nBut in Trump's mind there are many sides that he is trying to unite:\\nThe KKK side, the Nazi side, Southern Nationalists side, the 'poorly educated' unemployable white guy side, etc\"]\n",
      "\n",
      "Sample Neutral Comments:\n",
      "[\"Ya, its almost like we need to do something besides lay off all the state workers. Entitlements cost almost all of that $3.7 billion. So we have 2 choices. reduce entitlements and spend my money on my family, or increase taxes and spend my money on someone else's.\", \"That argument makes no sense, WM. Society moves forward, those that choose not to shouldn't think that those that did have to pay for their defunct lifestyle.\", 'Well then I certainly hope you are going to go to your local university the next time a men\\'s rights group or conservative speaker is coming and the SJW\\'s (or \"peacocks\" as Scott Adams calls them) are screaming and shouting and making threats to try and shut the event down. If you are at Dalhousie the young woman you mention is likely to be there with her pals trying to prevent the invited speaker(s) from being heard so maybe you\\'ll have a chance to explain the hypocrisy to her.', 'Key words: \"mythical and mystical\" and opening shipping routes. China recognizes climate change and acting on it. Think importing Chinese tourists (not those seeking wildlife trophy), exporting Alaskan Native made cultural items that benefit bush artisans, and cooperative renewable clean energy solutions.....Don\\'t focus on old energy economies alone. Think bigger, Alaska. Glad you had this friendly visitor. Mandarin and high tech energy system university investments anyone?', 'Gegonos, you are a comedian! Exactly how did any of these actions HELP people get healthcare?']\n"
     ]
    }
   ],
   "source": [
    "toxic_texts = [test_texts[i] for i, label in enumerate(predicted_labels) if label == 1]\n",
    "neutral_texts = [test_texts[i] for i, label in enumerate(predicted_labels) if label == 0]\n",
    "print(\"\\nSample Toxic Comments:\")\n",
    "print(toxic_texts[:5])\n",
    "print(\"\\nSample Neutral Comments:\")\n",
    "print(neutral_texts[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
